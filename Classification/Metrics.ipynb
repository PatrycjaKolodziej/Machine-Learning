{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-g4zNhPSX4BW"
   },
   "source": [
    "# Metryki klasyfikacji\n",
    "\n",
    "Aby poznać popularne metody oceny klasyfikatorów wygenerujemy sobie przykładowe sekwencje klas przykładów. Wykorzystamy w tym celu bibliotekę numpy oraz generator liczb losowych z rozkładu normalnego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = RandomState(30)\n",
    "\n",
    "random_1 = random.normal(loc = 0.0, size = 100)\n",
    "random_2 = random.logistic(loc = 1, size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.26405266  1.52790535 -0.97071094  0.47055962 -0.10069672  0.30379318\n",
      " -1.72596243  1.58509537  0.13429659 -1.10685547]\n",
      "[-0.34625296  2.7465497   0.46063247  3.2000744   0.12353606  1.56724961\n",
      "  2.32137633 -0.21323077  1.9572528   0.03456367]\n"
     ]
    }
   ],
   "source": [
    "print(random_1[:10])\n",
    "print(random_2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [1 if i >= 0 else 0 for i in random_1]\n",
    "y_pred = [1 if i >= 0 else 0 for i in random_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 0, 1, 0, 1, 1, 0]\n",
      "[0, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:10])\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbK2vwiXX4Be"
   },
   "source": [
    "## Macierz błędów\n",
    "\n",
    "Pierwszym krokiem będzie stworzenie macierzy błędów, czyli wyznaczenia true postives, true negatives, false positives i false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(truth, prediction):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    \n",
    "    for label_t, label_p in zip(truth, prediction):\n",
    "        if label_t == label_p:\n",
    "            if label_p == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        else:\n",
    "            if label_p == 1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                fn +=1\n",
    "    return tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, tn, fp, fn = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:30, TN:14\n",
      "Ile obserwacji zaklasyfikowaliśmy poprawnie: 44\n"
     ]
    }
   ],
   "source": [
    "print(f'TP:{tp}, TN:{tn}')\n",
    "print(f'Ile obserwacji zaklasyfikowaliśmy poprawnie: {tp+tn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP:43, FN:13\n",
      "Ile obserwacji zaklasyfikowaliśmy niepoprawnie: 56\n"
     ]
    }
   ],
   "source": [
    "print(f'FP:{fp}, FN:{fn}')\n",
    "print(f'Ile obserwacji zaklasyfikowaliśmy niepoprawnie: {fp+fn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUCbfBRoX4Bf"
   },
   "source": [
    "## Accuracy\n",
    "\n",
    "Pierwszą miarą jest miara dokładności "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = (tp+tn) / (tp+tn+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(truth, prediction):\n",
    "    tp, tn, fp, fn = confusion_matrix(truth, prediction)\n",
    "    print(tp, tn, fp, fn)\n",
    "    \n",
    "    return (tp+tn) / (tp+tn+fp+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzN5wkknX4Bf"
   },
   "source": [
    "Wynik dla analizowanych predykcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 14 43 13\n",
      "Dokładność: 0.44\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(y_test, y_pred)\n",
    "\n",
    "print(f'Dokładność: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDgmQCqzX4Bg"
   },
   "source": [
    "#### Problem\n",
    "Accuracy zachowuje się źle przy niezbalansowanych zbiorach. Wygenerujemy zbiór, w którym większość przykładów będzie negatywna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_3 = random.normal(loc = -1.5, size = 100)\n",
    "y_pred_2 = [1 if i >= 0 else 0 for i in random_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 52 5 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_test, y_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFio7HseX4Bh"
   },
   "source": [
    "Zakładając z góry, że wszystkie przykłady są negatywne uzyskujemy bardzo wysoką dokładność. Takie zachowanie jest w wielu przypadkach niepożądane - przypuśćmy, że próbujemy stworzyć klasyfikator do komórek rakowych, gdzie większość przypadków jest negatywna - dla takiego podejścia, zwrócenie informacji że wszystkie przypadki są negatywne da bardzo wysoką dokładność."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 92 8 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(100*[0], y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0, 1, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 1, 1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0, 0, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Y6fcinkX4Bi"
   },
   "source": [
    "## Recall\n",
    "\n",
    "Ta miara z kolei mówi o tym, jaką część dodatnich wyników wykrył klasyfikator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall = tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(truth, prediction):\n",
    "    tp, tn, fp, fn = confusion_matrix(truth, prediction)\n",
    "    \n",
    "    return tp / (tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976744186046512"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06976744186046512"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(y_test, y_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcIZ3w-LX4Bj"
   },
   "source": [
    "## Precision\n",
    "\n",
    "Jest to miara, która skupia się tylko na przykładach pozytywnych - mówi jaka część wyników wskazanych przez klasyfikator jako dodatnie jest rzeczywiście dodatnia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision = tp / (tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(truth, prediction):\n",
    "    tp, tn, fp, fn = confusion_matrix(truth, prediction)\n",
    "    \n",
    "    return tp / (tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.410958904109589"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(y_test, y_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9SoQbRPX4Bk"
   },
   "source": [
    "# F1 Score\n",
    "\n",
    "Jest to średnia harmoniczna precyzji i czułości. Ogólnie - im wyższy F1-score tym lepszy jest klasyfikator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_score = (2 * precision * recall)/(prec+rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(truth, predicted):\n",
    "    prec = precision(truth, predicted)\n",
    "    rec = recall(truth, predicted)\n",
    "    \n",
    "    return 2*prec*rec / (prec*rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnZA6fKdX4Bm"
   },
   "source": [
    "**Zadanie:** Sprawdź funckje f1_score, precision_score, recall_score z modułu scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976744186046512"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.410958904109589"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5172413793103448"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14, 43],\n",
       "       [13, 30]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.25      0.33        57\n",
      "           1       0.41      0.70      0.52        43\n",
      "\n",
      "    accuracy                           0.44       100\n",
      "   macro avg       0.46      0.47      0.43       100\n",
      "weighted avg       0.47      0.44      0.41       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Metrics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
